{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Deep Convolutional Neural Network to Recognize Fruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "I'm using the [fruits360 dataset](https://www.kaggle.com/moltean/fruits) from kaggle. I only read in ten random fruits at a time in order to spare my wimpy computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick 10 random fruits based on their containing folders in the training data\n",
    "n_fruits = 10 \n",
    "prediction_fruits = np.random.choice(os.listdir('fruits-360/Training/'), n_fruits)\n",
    "# alternately - load fruits from a prior random model run\n",
    "#prediction_fruits = np.load('model_fruits.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the fruits used for prediction -- there should have been 10 but I forgot to sample without replacement above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cherry Rainier', 'Granadilla', 'Guava', 'Mandarine',\n",
       "       'Passion Fruit', 'Pear Abate', 'Pitahaya Red', 'Strawberry',\n",
       "       'Tomato 1'], dtype='<U14')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_fruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the file paths to all of the training/testing images for each type of fruit\n",
    "train_img_urls = []\n",
    "test_img_urls = []\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "train_prefix = 'fruits-360/Training/%s/'\n",
    "test_prefix = 'fruits-360/Test/%s/'\n",
    "for i in prediction_fruits:\n",
    "    train_fruit_urls = [(train_prefix % i) + j for j in os.listdir(train_prefix % i)]\n",
    "    test_fruit_urls = [(test_prefix % i) + j for j in os.listdir(test_prefix % i)]\n",
    "    train_fruit_labels = [i] * len(train_fruit_urls)\n",
    "    test_fruit_labels = [i] * len(test_fruit_urls)\n",
    "    train_img_urls += train_fruit_urls \n",
    "    test_img_urls += test_fruit_urls \n",
    "    # collect the true labels (fruit name) for each training/testing sample\n",
    "    train_labels += train_fruit_labels\n",
    "    test_labels += test_fruit_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the images as BGR (OpenCV does this instead of RGB for some reason) data \n",
    "train_images = np.stack([cv2.imread(i, 1) for i in train_img_urls])\n",
    "test_images = np.stack([cv2.imread(i, 1) for i in test_img_urls])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are of size 100 x 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5398, 100, 100, 3)\n",
      "(1818, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the fruit names to a one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {e:i for i, e in enumerate(np.unique(test_labels))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cherry Rainier': 0,\n",
       " 'Granadilla': 1,\n",
       " 'Guava': 2,\n",
       " 'Mandarine': 3,\n",
       " 'Passion Fruit': 4,\n",
       " 'Pear Abate': 5,\n",
       " 'Pitahaya Red': 6,\n",
       " 'Strawberry': 7,\n",
       " 'Tomato 1': 8}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_int_labels = np.vectorize(label_mapping.get)(np.array(train_labels))\n",
    "test_int_labels = np.vectorize(label_mapping.get)(np.array(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one_hot_labels = to_categorical(train_int_labels, num_classes=n_fruits)\n",
    "test_one_hot_labels = to_categorical(test_int_labels, num_classes=n_fruits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup\n",
    "I used Keras to make a Convolutional Neural Network with the following structure:\n",
    "\n",
    "100 x 100 x 3 image  \n",
    "=>  \n",
    "Convolutional Layer (32 filters, 3x3 kernel, stride 2)  \n",
    "=>  \n",
    "Convolutional Layer (32 filters, 3x3 kernel, stride 2)  \n",
    "=>  \n",
    "Pooling Layer (Max Pooling, 2x2)  \n",
    "=>  \n",
    "Dropout Layer (Keep 75%)  \n",
    "=>  \n",
    "Convolutional Layer (64 filters, 3x3 kernel, stride 1)  \n",
    "=>  \n",
    "Convolutional Layer (64 filters, 3x3 kernel, stride 1)  \n",
    "=>  \n",
    "Pooling Layer (Max Pooling, 2x2)  \n",
    "=>  \n",
    "Dropout Layer (Keep 75%)  \n",
    "=>  \n",
    "Convolutional Layer (16 filters, 3x3 kernel, stride 1)  \n",
    "=>  \n",
    "Convolutional Layer (16 filters, 3x3 kernel, stride 1)  \n",
    "=>  \n",
    "Pooling Layer (Max Pooling, 2x2)  \n",
    "=>  \n",
    "Dropout Layer (Keep 75%)  \n",
    "=>  \n",
    "Flatten  \n",
    "=>  \n",
    "Softmax output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3,3), strides=(2,2), padding='same', activation='relu', input_shape=train_images.shape[1:]),\n",
    "    Conv2D(filters=32, kernel_size=(3,3), strides=(2,2), activation='relu'),\n",
    "\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    \n",
    "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),   \n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(filters=16, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    Conv2D(filters=16, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(n_fruits, activation='softmax')    \n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 50, 50, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 5, 5, 16)          9232      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 3, 3, 16)          2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               8704      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 90,954\n",
      "Trainable params: 90,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5398/5398 [==============================] - 319s 59ms/step - loss: 2.2373 - acc: 0.2544\n",
      "Epoch 2/10\n",
      "5398/5398 [==============================] - 312s 58ms/step - loss: 0.9713 - acc: 0.6078\n",
      "Epoch 3/10\n",
      "5398/5398 [==============================] - 312s 58ms/step - loss: 0.4984 - acc: 0.8194\n",
      "Epoch 4/10\n",
      "5398/5398 [==============================] - 318s 59ms/step - loss: 0.3351 - acc: 0.8824\n",
      "Epoch 5/10\n",
      "5398/5398 [==============================] - 311s 58ms/step - loss: 0.1579 - acc: 0.9457\n",
      "Epoch 6/10\n",
      "5398/5398 [==============================] - 308s 57ms/step - loss: 0.1174 - acc: 0.9598\n",
      "Epoch 7/10\n",
      "5398/5398 [==============================] - 313s 58ms/step - loss: 0.1013 - acc: 0.9654\n",
      "Epoch 8/10\n",
      "5398/5398 [==============================] - 270s 50ms/step - loss: 0.0892 - acc: 0.9696\n",
      "Epoch 9/10\n",
      "5398/5398 [==============================] - 250s 46ms/step - loss: 0.1052 - acc: 0.9676\n",
      "Epoch 10/10\n",
      "5398/5398 [==============================] - 249s 46ms/step - loss: 0.0677 - acc: 0.9754\n",
      "1818/1818 [==============================] - 28s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_images, train_one_hot_labels, epochs=10, batch_size=75)\n",
    "score = model.evaluate(test_images, test_one_hot_labels, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.025848573993855158, 0.9895489548954896]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternately -- load a saved model\n",
    "# model = load_model('deep-cnn-fruits.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the predictions to a one-dimensional vector and compute a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_predictions = np.round(model.predict(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class = np.argmax(one_hot_predictions,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[227,   0,   0,   0,  19,   0,   0,   0,   0],\n",
       "       [  0, 166,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0, 166,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0, 166,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0, 166,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0, 166,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 166,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 164,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 246]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=pred_class,y_true=test_int_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model and the fruits it was computed on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('deep-cnn-fruits.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('model_fruits.npy', np.unique(test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
